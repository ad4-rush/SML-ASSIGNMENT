{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18623, 10)\n",
      "(18623, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calculate_gini(labels):\n",
    "    n_labels = len(labels)\n",
    "    if n_labels == 0:\n",
    "        return 0\n",
    "    counts = np.bincount(labels)\n",
    "    probabilities = counts / n_labels\n",
    "    gini = 1 - np.sum(probabilities ** 2)\n",
    "    return gini\n",
    "\n",
    "def find_best_split(feature, labels):\n",
    "    sorted_indices = np.argsort(feature)\n",
    "    best_gini = float('inf')\n",
    "    best_split_value = None\n",
    "    for i in range(len(feature) - 1):\n",
    "        split_value = 0.5 * (feature[sorted_indices[i]] + feature[sorted_indices[i + 1]])\n",
    "        # print(split_value)\n",
    "        left_labels = labels[sorted_indices[:i + 1]]\n",
    "        right_labels = labels[sorted_indices[i + 1:]]\n",
    "        gini = (len(left_labels) * calculate_gini(left_labels) + len(right_labels) * calculate_gini(right_labels)) / len(labels)\n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_split_value = split_value\n",
    "    return best_gini, best_split_value\n",
    "\n",
    "def grow_decision_tree(features, labels, max_nodes):\n",
    "    n_features = features.shape[1]\n",
    "    print(\"hII\", features.shape)\n",
    "    best_split_dim = None\n",
    "    best_split_value = None\n",
    "    best_gini= float('inf')\n",
    "    \n",
    "    for dim in range(n_features):\n",
    "        gini, split_value = find_best_split(features[:,dim], labels)\n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_split_dim = dim\n",
    "            best_split_value = split_value\n",
    "    \n",
    "    left_indices = features[:, best_split_dim] <= best_split_value\n",
    "    right_indices = ~left_indices\n",
    "    left_labels = labels[left_indices]\n",
    "    right_labels = labels[right_indices]\n",
    "    left_features = features[left_indices]\n",
    "    right_features = features[right_indices]\n",
    "    gini_left = calculate_gini(left_labels)\n",
    "    gini_right = calculate_gini(right_labels)\n",
    "    \n",
    "    if max_nodes == 0:\n",
    "        node = {\n",
    "            'split_dim': best_split_dim,\n",
    "            'split_value': best_split_value,\n",
    "            'left': {'class': np.argmax(np.bincount(left_labels))},\n",
    "            'gini_left': gini_left,\n",
    "            'gini_right': gini_right,\n",
    "            'right': {'class': np.argmax(np.bincount(right_labels))}\n",
    "        }\n",
    "        return node\n",
    "        \n",
    "    if gini_left >= gini_right:\n",
    "        node = {\n",
    "            'split_dim': best_split_dim,\n",
    "            'split_value': best_split_value,\n",
    "            'left': grow_decision_tree(left_features, left_labels, max_nodes-1),\n",
    "            'gini_left': gini_left,\n",
    "            'gini_right': gini_right,\n",
    "            'right': {'class': np.argmax(np.bincount(right_labels))}\n",
    "        }\n",
    "        return node\n",
    "    else:\n",
    "        node = {\n",
    "            'split_dim': best_split_dim,\n",
    "            'split_value': best_split_value,\n",
    "            'left': {'class': np.argmax(np.bincount(left_labels))},\n",
    "            'gini_left': gini_left,\n",
    "            'gini_right': gini_right,\n",
    "            'right': grow_decision_tree(right_features, right_labels, max_nodes-1)\n",
    "        }\n",
    "        return node\n",
    "def classify_sample(sample, node):\n",
    "    if 'class' in node:\n",
    "        return node['class']\n",
    "    elif sample[node['split_dim']] <= node['split_value']:\n",
    "        return classify_sample(sample, node['left'])\n",
    "    else:\n",
    "        return classify_sample(sample, node['right'])\n",
    "\n",
    "\n",
    "def classify_samples(samples, node):\n",
    "    predictions = []\n",
    "    print(samples.shape)\n",
    "    for sample in samples:\n",
    "        class_prediction = classify_sample(sample, node)\n",
    "        predictions.append(class_prediction)\n",
    "    return predictions\n",
    "\n",
    "with np.load(\"C:\\Shared_archcraft\\SML\\Assignment3\\mnist.npz\") as data:\n",
    "    x_train, y_train = data['x_train'], data['y_train']\n",
    "    x_test, y_test = data['x_test'], data['y_test']\n",
    "\n",
    "\n",
    "def pca(x):\n",
    "    \n",
    "    X_mean = np.mean(x, axis=0)\n",
    "    X_centered = x - X_mean\n",
    "    pca = PCA(n_components=10)\n",
    "\n",
    "    X_flattened = X_centered.reshape(X_centered.shape[0], -1)\n",
    "\n",
    "    pca.fit(X_flattened)\n",
    "\n",
    "    X_pca = pca.transform(X_flattened)\n",
    "    print(X_pca.shape)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "\n",
    "train_mask = np.isin(y_train, [0, 1, 2])\n",
    "x_train_012 = x_train[train_mask]\n",
    "y_train_012 = y_train[train_mask]\n",
    "\n",
    "x_train_012 = x_train_012.reshape(x_train_012.shape[0], -1)\n",
    "\n",
    "mean_vec = np.mean(x_train_012, axis=0)\n",
    "\n",
    "cov_mat = np.cov(x_train_012.T)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "sorted_indices = np.argsort(eig_vals)[::-1]\n",
    "\n",
    "top_eig_vecs = eig_vecs[:, sorted_indices[:10]]\n",
    "\n",
    "x_train_reduced = pca(x_train_012)\n",
    "print(x_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hII (18623, 10)\n",
      "hII (11923, 10)\n",
      "{'split_dim': 0, 'split_value': -624.6830522025067, 'left': {'class': 1}, 'gini_left': 0.09149993316997107, 'gini_right': 0.528841468983415, 'right': {'split_dim': 1, 'split_value': 183.30346470912838, 'left': {'class': 0}, 'gini_left': 0.2631231332541133, 'gini_right': 0.20659939939939953, 'right': {'class': 2}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def q1():\n",
    "    node = grow_decision_tree(x_train_reduced, y_train_012, 1)\n",
    "    print(node)\n",
    "    return node\n",
    "node = q1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3147, 10)\n",
      "{'split_dim': 0, 'split_value': -624.6830522025067, 'left': {'class': 1}, 'gini_left': 0.09149993316997107, 'gini_right': 0.528841468983415, 'right': {'split_dim': 1, 'split_value': 183.30346470912838, 'left': {'class': 0}, 'gini_left': 0.2631231332541133, 'gini_right': 0.20659939939939953, 'right': {'class': 2}}}\n",
      "(3147, 10)\n",
      "Total Accuracy: 0.899904671115348\n",
      "Class-wise Accuracy: {0: 0.9428571428571428, 1: 0.9480176211453745, 2: 0.8062015503875969}\n"
     ]
    }
   ],
   "source": [
    "def q2_helper(x_test_012, y_test_012,node):\n",
    "\n",
    "    x_test_reduced = pca(x_test_012)\n",
    "    print(node)\n",
    "    test_predictions = classify_samples(x_test_reduced, node)\n",
    "\n",
    "    total_accuracy = np.mean(test_predictions == y_test_012)\n",
    "\n",
    "    class_wise_accuracy = {}\n",
    "    for i in [0, 1, 2]:\n",
    "        mask = y_test_012 == i\n",
    "        class_accuracy = np.mean(np.array(test_predictions)[mask] == i)\n",
    "        class_wise_accuracy[i] = class_accuracy\n",
    "\n",
    "    print(\"Total Accuracy:\", total_accuracy)\n",
    "    print(\"Class-wise Accuracy:\", class_wise_accuracy)\n",
    "def q2(node):\n",
    "    train_mask = np.isin(y_test, [0, 1, 2])\n",
    "    x_test_012 = x_test[train_mask]\n",
    "    y_test_012 = y_test[train_mask]\n",
    "    q2_helper(x_test_012, y_test_012,node)\n",
    "\n",
    "q2(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n",
      "hII (500, 10)\n",
      "hII (311, 10)\n",
      "(500, 10)\n",
      "hII (500, 10)\n",
      "hII (309, 10)\n",
      "(500, 10)\n",
      "hII (500, 10)\n",
      "hII (312, 10)\n",
      "(500, 10)\n",
      "hII (500, 10)\n",
      "hII (308, 10)\n",
      "(500, 10)\n",
      "hII (500, 10)\n",
      "hII (327, 10)\n"
     ]
    }
   ],
   "source": [
    "def majority_vote(predictions):\n",
    "    return np.bincount(predictions).argmax()\n",
    "def predict_majority_vote(x_test, trees):\n",
    "    predictions = []\n",
    "    for sample in x_test:\n",
    "        tree_predictions = [classify_sample(sample,tree) for tree in trees]\n",
    "        majority_prediction = majority_vote(tree_predictions)\n",
    "        predictions.append(majority_prediction)\n",
    "    return predictions\n",
    "def q3_helper():\n",
    "\n",
    "    num_trees = 5\n",
    "    trees = []\n",
    "    def bootstrap_sample(x_train, y_train, sample_size=500):\n",
    "        indices = np.random.choice(len(x_train), size=sample_size, replace=True)\n",
    "        x_sampled = x_train[indices]\n",
    "        y_sampled = y_train[indices]\n",
    "        return x_sampled, y_sampled\n",
    "    \n",
    "    \n",
    "    for _ in range(num_trees):\n",
    "        x_sampled, y_sampled = bootstrap_sample(x_train_012, y_train_012)\n",
    "        x_sampled = pca(x_sampled)\n",
    "        tree = grow_decision_tree(x_sampled, y_sampled , 1)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "trees = q3_helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3147, 10)\n",
      "Total Accuracy: 0.9062599300921512\n",
      "Class-wise Accuracy: {0: 0.9714285714285714, 1: 0.9726872246696036, 2: 0.7713178294573644}\n"
     ]
    }
   ],
   "source": [
    "def q3(trees):\n",
    "    train_mask = np.isin(y_test, [0, 1, 2])\n",
    "    x_test_012 = x_test[train_mask]\n",
    "    x_test_012 = pca(x_test_012)\n",
    "    test_predictions = predict_majority_vote(x_test_012, trees)\n",
    "\n",
    "    total_accuracy = np.mean(test_predictions == y_test[np.isin(y_test, [0, 1, 2])])\n",
    "\n",
    "    class_wise_accuracy = {}\n",
    "    for i in [0, 1, 2]:\n",
    "        mask = y_test[np.isin(y_test, [0, 1, 2])] == i\n",
    "        class_accuracy = np.mean(np.array(test_predictions)[mask] == i)\n",
    "        class_wise_accuracy[i] = class_accuracy\n",
    "\n",
    "    print(\"Total Accuracy:\", total_accuracy)\n",
    "    print(\"Class-wise Accuracy:\", class_wise_accuracy)\n",
    "\n",
    "q3(trees)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
