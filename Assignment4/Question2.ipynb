{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5923\n",
      "6742\n",
      "(10665,)\n",
      "(10665, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with np.load(\"C:\\Shared_archcraft\\SML\\Assignment4\\mnist.npz\") as data:\n",
    "    x_train, y_train = data['x_train'], data['y_train']\n",
    "    x_test, y_test = data['x_test'], data['y_test']\n",
    "\n",
    "train_mask = np.isin(y_train, [0])\n",
    "x_train_0 = x_train[train_mask]\n",
    "y_train_0 = [0]*len(x_train_0)\n",
    "\n",
    "train_mask = np.isin(y_train, [1])\n",
    "x_train_1 = x_train[train_mask]\n",
    "y_train_1 = y_train[train_mask]\n",
    "\n",
    "train_mask = np.isin(y_train, [0, 1])\n",
    "x_train_01 = x_train[train_mask]\n",
    "y_train_01 = y_train[train_mask]\n",
    "\n",
    "print(len(y_train_0))\n",
    "print(len(y_train_1))\n",
    "\n",
    "\n",
    "x_test_1 = x_train_1[:1000]\n",
    "y_test_1 = y_train_1[:1000]\n",
    "x_test_0 = x_train_0[:1000]\n",
    "y_test_0 = y_train_0[:1000]\n",
    "\n",
    "x_train_0 = x_train_0[1000:]\n",
    "y_train_0 = y_train_0[1000:]\n",
    "x_train_1 = x_train_1[1000:]\n",
    "y_train_1 = y_train_1[1000:]\n",
    "\n",
    "x_real_train = np.concatenate([x_train_0, x_train_1], axis=0)\n",
    "y_real_train = np.concatenate([y_train_0, y_train_1], axis=0)\n",
    "x_real_test = np.concatenate([x_test_0, x_test_1], axis=0)\n",
    "y_real_test = np.concatenate([y_test_0, y_test_1], axis=0)\n",
    "\n",
    "# Reshape x_real_train\n",
    "# x_real_train = x_real_train.reshape(-1, 28, 28)\n",
    "print(y_real_train.shape)\n",
    "print(x_real_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(x):\n",
    "    X_mean = np.mean(x, axis=0)\n",
    "    X_centered = x - X_mean\n",
    "    X_centered_2d = X_centered.reshape(X_centered.shape[0], -1)  # Ensure X_centered is 2D\n",
    "    cov_matrix = np.cov(X_centered_2d, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    p = 5\n",
    "    top_indices = np.argsort(eigenvalues)[::-1][:p]\n",
    "    pca_matrix = eigenvectors[:, top_indices]\n",
    "    \n",
    "    x_reduced = np.dot(X_centered_2d, pca_matrix)\n",
    "    \n",
    "    print(x_reduced.shape)\n",
    "    return x_reduced\n",
    "\n",
    "# pca(x_real_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumOfStumps = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residue = y_real_train.copy()\n",
    "# residue = residue.astype(np.float64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.idx = None\n",
    "        self.split_value = None\n",
    "        self.left_mean = None\n",
    "        self.right_mean = None\n",
    "        self.min_error = float('inf')\n",
    "\n",
    "    def train(self, X, y):\n",
    "        num_samples = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "\n",
    "        # min_error = float('inf')\n",
    "\n",
    "        for idx in range(num_features):\n",
    "            values = np.unique(X[:, idx])\n",
    "            for split_value in values:\n",
    "                left_indices = X[:, idx] <= split_value\n",
    "                right_indices = X[:, idx] > split_value\n",
    "\n",
    "                left_mean = np.mean(y[left_indices])\n",
    "                right_mean = np.mean(y[right_indices])\n",
    "\n",
    "                residuals = y - left_mean * left_indices.astype(int) - right_mean * right_indices.astype(int)\n",
    "                error = np.sum(residuals ** 2)\n",
    "\n",
    "                if error < self.min_error:\n",
    "                    self.min_error = error\n",
    "                    self.idx = idx\n",
    "                    self.split_value = split_value\n",
    "                    self.left_mean = left_mean\n",
    "                    self.right_mean = right_mean\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_samples = X.shape[0]\n",
    "        predictions = np.zeros(num_samples)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            if X[i, self.idx] <= self.split_value:\n",
    "                predictions[i] = self.left_mean\n",
    "            else:\n",
    "                predictions[i] = self.right_mean\n",
    "\n",
    "        return predictions\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_pred = [np.mean(y)]*len(y)  # Initialize with the mean\n",
    "        residuals = y - y_pred\n",
    "        # print(y_pred)\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            estimator = DecisionStump()\n",
    "            estimator.train(X, residuals)\n",
    "            y_pred = (y_pred + self.learning_rate * estimator.predict(X)).astype(np.float64)  # Ensure y_pred is float\n",
    "            residuals = y - y_pred\n",
    "            print(residuals)\n",
    "            self.estimators.append(estimator)\n",
    "            print(estimator.min_error)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            y_pred = (y_pred + self.learning_rate * estimator.predict(X)).astype(np.float64)  # Ensure y_pred is float\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "# Example usage:\n",
    "# model = GradientBoosting(n_estimators=100, learning_rate=0.1)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4504985 -0.4504985 -0.4504985 ...  0.4502006  0.4502006  0.4502006]\n",
      "6.971062739564653\n",
      "[-0.40594716 -0.40594716 -0.40594716 ...  0.40538114  0.40538114\n",
      "  0.40538114]\n",
      "6.971062739564653\n",
      "[-0.36585095 -0.36585095 -0.36585095 ...  0.36504363  0.36504363\n",
      "  0.36504363]\n",
      "6.971062739564653\n",
      "[-0.32976436 -0.32976436 -0.32976436 ...  0.32873987  0.32873987\n",
      "  0.32873987]\n",
      "6.971062739564654\n",
      "[-0.29728643 -0.29728643 -0.29728643 ...  0.29606648  0.29606648\n",
      "  0.29606648]\n",
      "6.971062739564654\n",
      "[-0.26805629 -0.26805629 -0.26805629 ...  0.26666044  0.26666044\n",
      "  0.26666044]\n",
      "6.971062739564653\n",
      "[-0.24174916 -0.24174916 -0.24174916 ...  0.240195    0.240195\n",
      "  0.240195  ]\n",
      "6.971062739564654\n",
      "[-0.21807275 -0.21807275 -0.21807275 ...  0.2163761   0.2163761\n",
      "  0.2163761 ]\n",
      "6.971062739564654\n",
      "[-0.19676398 -0.19676398 -0.19676398 ...  0.19493909  0.19493909\n",
      "  0.19493909]\n",
      "6.971062739564654\n",
      "[-0.17758609 -0.17758609 -0.17758609 ...  0.17564578  0.17564578\n",
      "  0.17564578]\n",
      "6.971062739564654\n",
      "[-0.16032598 -0.16032598 -0.16032598 ...  0.15828181  0.15828181\n",
      "  0.15828181]\n",
      "6.971062739564655\n",
      "[-0.14479189 -0.14479189 -0.14479189 ...  0.14265423  0.14265423\n",
      "  0.14265423]\n",
      "6.971062739564654\n",
      "[-0.1308112  -0.1308112  -0.1308112  ...  0.12858941  0.12858941\n",
      "  0.12858941]\n",
      "6.971062739564653\n",
      "[-0.11822859 -0.11822859 -0.11822859 ...  0.11593107  0.11593107\n",
      "  0.11593107]\n",
      "6.971062739564653\n",
      "[-0.10690423 -0.10690423 -0.10690423 ...  0.10453856  0.10453856\n",
      "  0.10453856]\n",
      "6.971062739564654\n",
      "[-0.09679711 -0.09679711 -0.09679711 ...  0.09418592  0.09418592\n",
      "  0.09418592]\n",
      "6.944042718783251\n",
      "[-0.08732253 -0.08732253 -0.08732253 ...  0.08517351  0.08517351\n",
      "  0.08517351]\n",
      "6.817222627481856\n",
      "[-0.0787954  -0.0787954  -0.0787954  ...  0.07706235  0.07706235\n",
      "  0.07706235]\n",
      "6.817222627481856\n",
      "[-0.07137074 -0.07137074 -0.07137074 ...  0.06945733  0.06945733\n",
      "  0.06945733]\n",
      "6.728998362826029\n",
      "[-0.06468854 -0.06468854 -0.06468854 ...  0.06261281  0.06261281\n",
      "  0.06261281]\n",
      "6.728998362826029\n",
      "[-0.05842482 -0.05842482 -0.05842482 ...  0.05665463  0.05665463\n",
      "  0.05665463]\n",
      "6.674219286476578\n",
      "[-0.05278746 -0.05278746 -0.05278746 ...  0.05129227  0.05129227\n",
      "  0.05129227]\n",
      "6.6742192864765775\n",
      "[-0.04787869 -0.04787869 -0.04787869 ...  0.04626426  0.04626426\n",
      "  0.04626426]\n",
      "6.63512951313643\n",
      "[-0.04319532 -0.04319532 -0.04319532 ...  0.04196705  0.04196705\n",
      "  0.04196705]\n",
      "6.608419352209079\n",
      "[-0.03928245 -0.03928245 -0.03928245 ...  0.03777034  0.04587992\n",
      "  0.03777034]\n",
      "6.584511246090584\n",
      "[-0.0353542  -0.0353542  -0.0353542  ...  0.03434232  0.0424519\n",
      "  0.03434232]\n",
      "6.551519602341396\n",
      "[-0.03215224 -0.03215224 -0.03215224 ...  0.03090809  0.04565386\n",
      "  0.03090809]\n",
      "6.5337685631712\n",
      "[-0.02893701 -0.02893701 -0.02893701 ...  0.0281023   0.04284807\n",
      "  0.0281023 ]\n",
      "6.510916750858847\n",
      "[-0.02631685 -0.02631685 -0.02631685 ...  0.02529207  0.04546823\n",
      "  0.02529207]\n",
      "6.4997067687436\n",
      "[-0.02368516 -0.02368516 -0.02368516 ...  0.0229955   0.04317167\n",
      "  0.0229955 ]\n",
      "6.48378977758397\n",
      "[-0.02154114 -0.02154114 -0.02154114 ...  0.02069595  0.04531569\n",
      "  0.02069595]\n",
      "6.476831776512573\n",
      "[-0.01938702 -0.01938702 -0.01938702 ...  0.01881615  0.04343589\n",
      "  0.01881615]\n",
      "6.4656757205512525\n",
      "[-0.01763267 -0.01763267 -0.01763267 ...  0.01693453  0.04519024\n",
      "  0.01693453]\n",
      "6.461461054185917\n",
      "[-0.0158694  -0.0158694  -0.0158694  ...  0.0153958   0.04365151\n",
      "  0.0153958 ]\n",
      "6.453587846756106\n",
      "[-0.01443395 -0.01443395 -0.01443395 ...  0.01385622  0.04508697\n",
      "  0.01385622]\n",
      "6.451125922699939\n",
      "[-0.01299055 -0.01299055 -0.01299055 ...  0.01259663  0.04382737\n",
      "  0.01259663]\n",
      "6.445527700123713\n",
      "[-0.0117886  -0.0117886  -0.0117886  ...  0.01136548  0.04259622\n",
      "  0.01136548]\n",
      "6.444100422568233\n",
      "[-0.01060974 -0.01060974 -0.01060974 ...  0.01033673  0.04156748\n",
      "  0.01033673]\n",
      "6.4412772920857995\n",
      "[-0.00964598 -0.00964598 -0.00964598 ...  0.00930306  0.04253124\n",
      "  0.00930306]\n",
      "6.43849848530602\n",
      "[-0.01014063 -0.01014063 -0.00786635 ...  0.00880841  0.04203659\n",
      "  0.00880841]\n",
      "6.423825506434872\n",
      "[-0.00921954 -0.00921954 -0.00694526 ...  0.00800461  0.04123279\n",
      "  0.00800461]\n",
      "6.418359822584792\n",
      "[-0.00962595 -0.00962595 -0.00533474 ...  0.00759819  0.04082638\n",
      "  0.00759819]\n",
      "6.407392318863292\n",
      "[-0.00883315 -0.00883315 -0.00454194 ...  0.00690635  0.04013453\n",
      "  0.00690635]\n",
      "6.4037293585672135\n",
      "[-0.00917628 -0.00917628 -0.00311636 ...  0.00656322  0.03979141\n",
      "  0.00656322]\n",
      "6.394753623140565\n",
      "[-0.00849336 -0.00849336 -0.00243343 ...  0.00596726  0.03919544\n",
      "  0.00596726]\n",
      "6.39259700270294\n",
      "[-0.00877208 -0.00877208 -0.00111029 ...  0.00568853  0.03891672\n",
      "  0.00568853]\n",
      "6.384772026014847\n",
      "[-9.06462966e-03 -9.06462966e-03 -6.70011651e-05 ...  5.39598591e-03\n",
      "  3.86241689e-02  5.39598591e-03]\n",
      "6.383474437030036\n",
      "[-0.00850001 -0.00850001  0.00049762 ...  0.00490327  0.03813145\n",
      "  0.00490327]\n",
      "6.37727929983267\n",
      "[-0.00877919 -0.00762077  0.00137686 ...  0.00462409  0.03785227\n",
      "  0.00462409]\n",
      "6.373253530649663\n",
      "[-0.00899821 -0.00783978  0.00241657 ...  0.00440507  0.03763325\n",
      "  0.00440507]\n",
      "6.367476762232633\n",
      "[-0.00851498 -0.00735655  0.0028998  ...  0.00398337  0.03721155\n",
      "  0.00398337]\n",
      "6.363610453336895\n",
      "[-0.00873157 -0.00757314  0.00380544 ...  0.00376678  0.03699496\n",
      "  0.00376678]\n",
      "6.357392068711892\n",
      "[-0.00791494 -0.00675651  0.00359097 ...  0.00355231  0.03678049\n",
      "  0.00355231]\n",
      "6.354140448469808\n",
      "[-0.00810779 -0.00694937  0.00450649 ...  0.00335945  0.03658764\n",
      "  0.00335945]\n",
      "6.347200905902618\n",
      "[-0.0074895  -0.00633107  0.00512478 ...  0.00309949  0.03632767\n",
      "  0.00309949]\n",
      "6.34365702184155\n",
      "[-0.00766945 -0.00550004  0.00494482 ...  0.00291953  0.03614772\n",
      "  0.00291953]\n",
      "6.339786218267436\n",
      "[-0.00787627 -0.00570685  0.00568237 ...  0.00271272  0.0359409\n",
      "  0.00271272]\n",
      "6.3335064810410735\n",
      "[-0.00717319 -0.00500378  0.0054966  ...  0.00252695  0.03575513\n",
      "  0.00252695]\n",
      "6.33209526901357\n",
      "[-0.00736453 -0.00519512  0.00617896 ...  0.00233561  0.03556379\n",
      "  0.00233561]\n",
      "6.327140905556271\n",
      "[-0.00685042 -0.00468101  0.00669307 ...  0.00208694  0.03531513\n",
      "  0.00208694]\n",
      "6.3227240572739465\n",
      "[-0.00619993 -0.00403052  0.0065212  ...  0.00191507  0.03514325\n",
      "  0.00191507]\n",
      "6.321073962029858\n",
      "[-0.006354   -0.00418458  0.00725257 ...  0.001761    0.03498919\n",
      "  0.001761  ]\n",
      "6.316650160720063\n",
      "[-0.00651324 -0.00434382  0.00791841 ...  0.00160176  0.03482995\n",
      "  0.00160176]\n",
      "6.313698289970662\n",
      "[-0.00656091 -0.0043915   0.00787074 ...  0.00155409  0.03478227\n",
      "  0.00155409]\n",
      "6.311987926579588\n",
      "[-0.00596434 -0.00379493  0.00771311 ...  0.00139647  0.03462465\n",
      "  0.00139647]\n",
      "6.308479458685863\n",
      "[-0.0061282  -0.00395878  0.00829745 ...  0.00123261  0.0344608\n",
      "  0.00123261]\n",
      "6.304564160336142\n",
      "[-0.00569445 -0.00352503  0.0087312  ...  0.00103269  0.03426087\n",
      "  0.00103269]\n",
      "6.302731279818907\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m pca(x_real_test)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoosting(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [6], line 61\u001b[0m, in \u001b[0;36mGradientBoosting.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators):\n\u001b[0;32m     60\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m DecisionStump()\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresiduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)  \u001b[38;5;66;03m# Ensure y_pred is float\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m y_pred\n",
      "Cell \u001b[1;32mIn [6], line 26\u001b[0m, in \u001b[0;36mDecisionStump.train\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     23\u001b[0m left_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y[left_indices])\n\u001b[0;32m     24\u001b[0m right_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y[right_indices])\n\u001b[1;32m---> 26\u001b[0m residuals \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m \u001b[43mleft_mean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m right_mean \u001b[38;5;241m*\u001b[39m right_indices\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     27\u001b[0m error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(residuals \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_error:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = pca(x_real_test)\n",
    "model = GradientBoosting(n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X, y_real_test)\n",
    "# y_pred = model.predict(X_test)\n",
    "# X = pca(x_real_train)\n",
    "# model = GradientBoosting(n_estimators=100, learning_rate=0.1)\n",
    "# model.fit(X, y_real_train)\n",
    "# # y_pred = model.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
